{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "adjacent-knight",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "from hazm import *\n",
    "from hazm import utils as utl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import feature_selection\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold, mutual_info_classif, mutual_info_regression\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import (CountVectorizer, \n",
    "                                             TfidfVectorizer,\n",
    "                                             TfidfTransformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-newark",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "offshore-prerequisite",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('vehicles.csv')\n",
    "train = pd.DataFrame(train)\n",
    "\n",
    "train['mileage'].fillna(value=train['mileage'].mean(), inplace=True)\n",
    "train['year'].fillna(value=train['year'].value_counts().idxmax(), inplace=True)\n",
    "train['brand'].fillna(value='سایر', inplace=True)\n",
    "train['year'] = train['year'].replace(to_replace='<1366', value='1355')\n",
    "\n",
    "train['year'] = list(map(int, train['year']))\n",
    "\n",
    "\n",
    "date_dict = {'Saturday': 0,\n",
    "            'Sunday':1,\n",
    "            'Monday':2,\n",
    "            'Tuesday':3,\n",
    "            'Wednesday':4,\n",
    "            'Thursday':5,\n",
    "            'Friday':6}\n",
    "\n",
    "def date_converter(x):\n",
    "    x = x.split()\n",
    "    day = date_dict[x[0]]\n",
    "    \n",
    "    hour = 0\n",
    "    if x[1][2] == 'A':\n",
    "        if int(x[1][:2]) == 12:\n",
    "            hour = 0\n",
    "        hour = int(x[1][:2])\n",
    "    else:\n",
    "        if int(x[1][:2]) == 12:\n",
    "            hour = 12\n",
    "        hour = int(x[1][:2]) + 12\n",
    "        \n",
    "    return day * 24 + hour\n",
    "\n",
    "train['created_at'] = list(map(date_converter, train['created_at']))\n",
    "train['category'] = train['category'].replace(to_replace = ['light', 'heavy'], value = [0, 1])\n",
    "\n",
    "index = 0\n",
    "brand_dict = dict()\n",
    "for i in train['brand'].unique():\n",
    "    brand_dict.update({i:index})\n",
    "    index += 1\n",
    "train['brand'] = train['brand'].replace(brand_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-hamilton",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "chronic-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "normalizer = Normalizer()\n",
    "lemmatizer = Lemmatizer()\n",
    "stop_words = open('stopwords', 'r').read().splitlines()\n",
    "stop_words = [lemmatizer.lemmatize(w) for w in stop_words]\n",
    "stop_words.append('\\n')\n",
    "stop_words.append('\\r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-place",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "indoor-parent",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = train.drop('description', 1)\n",
    "\n",
    "for index,row in train.iterrows():\n",
    "    normalizer.normalize(row['title'])\n",
    "    new_list = list()\n",
    "    for w in word_tokenize(row['title']):\n",
    "        word = lemmatizer.lemmatize(w)\n",
    "        if word not in stop_words:\n",
    "            new_list.append(w)\n",
    "    row['title'] = new_list   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "modern-firewall",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 130443 entries, 0 to 130442\n",
      "Data columns (total 47 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   brand        130443 non-null  int64  \n",
      " 1   category     130443 non-null  int64  \n",
      " 2   created_at   130443 non-null  int64  \n",
      " 3   image_count  130443 non-null  int64  \n",
      " 4   mileage      130443 non-null  float64\n",
      " 5   price        130443 non-null  int64  \n",
      " 6   year         130443 non-null  int64  \n",
      " 7   206          130443 non-null  float64\n",
      " 8   405          130443 non-null  float64\n",
      " 9   83           130443 non-null  float64\n",
      " 10  89           130443 non-null  float64\n",
      " 11  90           130443 non-null  float64\n",
      " 12  93           130443 non-null  float64\n",
      " 13  ال           130443 non-null  float64\n",
      " 14  ام           130443 non-null  float64\n",
      " 15  ای           130443 non-null  float64\n",
      " 16  بدون         130443 non-null  float64\n",
      " 17  بک           130443 non-null  float64\n",
      " 18  بی           130443 non-null  float64\n",
      " 19  تاکسی        130443 non-null  float64\n",
      " 20  تمیز         130443 non-null  float64\n",
      " 21  تیبا         130443 non-null  float64\n",
      " 22  تیپ          130443 non-null  float64\n",
      " 23  خودرو        130443 non-null  float64\n",
      " 24  دار          130443 non-null  float64\n",
      " 25  دوگانه       130443 non-null  float64\n",
      " 26  رنگ          130443 non-null  float64\n",
      " 27  سال          130443 non-null  float64\n",
      " 28  سالم         130443 non-null  float64\n",
      " 29  سفید         130443 non-null  float64\n",
      " 30  سمند         130443 non-null  float64\n",
      " 31  سوز          130443 non-null  float64\n",
      " 32  فابریک       130443 non-null  float64\n",
      " 33  فروش         130443 non-null  float64\n",
      " 34  فول          130443 non-null  float64\n",
      " 35  مدادی        130443 non-null  float64\n",
      " 36  مدل          130443 non-null  float64\n",
      " 37  مشکی         130443 non-null  float64\n",
      " 38  نیسان        130443 non-null  float64\n",
      " 39  هاچ          130443 non-null  float64\n",
      " 40  وانت         130443 non-null  float64\n",
      " 41  وی           130443 non-null  float64\n",
      " 42  پارس         130443 non-null  float64\n",
      " 43  پراید        130443 non-null  float64\n",
      " 44  پژو          130443 non-null  float64\n",
      " 45  پیکان        130443 non-null  float64\n",
      " 46  کارخانه      130443 non-null  float64\n",
      "dtypes: float64(41), int64(6)\n",
      "memory usage: 46.8 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 130443 entries, 0 to 130442\n",
      "Data columns (total 40 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   206      130443 non-null  float64\n",
      " 1   405      130443 non-null  float64\n",
      " 2   83       130443 non-null  float64\n",
      " 3   89       130443 non-null  float64\n",
      " 4   90       130443 non-null  float64\n",
      " 5   93       130443 non-null  float64\n",
      " 6   ال       130443 non-null  float64\n",
      " 7   ام       130443 non-null  float64\n",
      " 8   ای       130443 non-null  float64\n",
      " 9   بدون     130443 non-null  float64\n",
      " 10  بک       130443 non-null  float64\n",
      " 11  بی       130443 non-null  float64\n",
      " 12  تاکسی    130443 non-null  float64\n",
      " 13  تمیز     130443 non-null  float64\n",
      " 14  تیبا     130443 non-null  float64\n",
      " 15  تیپ      130443 non-null  float64\n",
      " 16  خودرو    130443 non-null  float64\n",
      " 17  دار      130443 non-null  float64\n",
      " 18  دوگانه   130443 non-null  float64\n",
      " 19  رنگ      130443 non-null  float64\n",
      " 20  سال      130443 non-null  float64\n",
      " 21  سالم     130443 non-null  float64\n",
      " 22  سفید     130443 non-null  float64\n",
      " 23  سمند     130443 non-null  float64\n",
      " 24  سوز      130443 non-null  float64\n",
      " 25  فابریک   130443 non-null  float64\n",
      " 26  فروش     130443 non-null  float64\n",
      " 27  فول      130443 non-null  float64\n",
      " 28  مدادی    130443 non-null  float64\n",
      " 29  مدل      130443 non-null  float64\n",
      " 30  مشکی     130443 non-null  float64\n",
      " 31  نیسان    130443 non-null  float64\n",
      " 32  هاچ      130443 non-null  float64\n",
      " 33  وانت     130443 non-null  float64\n",
      " 34  وی       130443 non-null  float64\n",
      " 35  پارس     130443 non-null  float64\n",
      " 36  پراید    130443 non-null  float64\n",
      " 37  پژو      130443 non-null  float64\n",
      " 38  پیکان    130443 non-null  float64\n",
      " 39  کارخانه  130443 non-null  float64\n",
      "dtypes: float64(40)\n",
      "memory usage: 39.8 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>category</th>\n",
       "      <th>created_at</th>\n",
       "      <th>image_count</th>\n",
       "      <th>mileage</th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>206</th>\n",
       "      <th>405</th>\n",
       "      <th>83</th>\n",
       "      <th>...</th>\n",
       "      <th>مشکی</th>\n",
       "      <th>نیسان</th>\n",
       "      <th>هاچ</th>\n",
       "      <th>وانت</th>\n",
       "      <th>وی</th>\n",
       "      <th>پارس</th>\n",
       "      <th>پراید</th>\n",
       "      <th>پژو</th>\n",
       "      <th>پیکان</th>\n",
       "      <th>کارخانه</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>4</td>\n",
       "      <td>100862.291944</td>\n",
       "      <td>-1</td>\n",
       "      <td>1393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>180000.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>1366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>290000.000000</td>\n",
       "      <td>8500000</td>\n",
       "      <td>1381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.488448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>175000.000000</td>\n",
       "      <td>19500000</td>\n",
       "      <td>1372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>4</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>23900000</td>\n",
       "      <td>1391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.667040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130438</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>2</td>\n",
       "      <td>100862.291944</td>\n",
       "      <td>48000000</td>\n",
       "      <td>1393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130439</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>4</td>\n",
       "      <td>100862.291944</td>\n",
       "      <td>-1</td>\n",
       "      <td>1393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130440</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>3</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>1392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130441</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>4</td>\n",
       "      <td>123000.000000</td>\n",
       "      <td>6900000</td>\n",
       "      <td>1379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130442</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>3</td>\n",
       "      <td>43000.000000</td>\n",
       "      <td>17400000</td>\n",
       "      <td>1393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.396567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.729655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130443 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        brand  category  created_at  image_count        mileage     price  \\\n",
       "0           0         1          91            4  100862.291944        -1   \n",
       "1           0         0         100            3  180000.000000        -1   \n",
       "2           1         0         107            0  290000.000000   8500000   \n",
       "3           2         0         109            3  175000.000000  19500000   \n",
       "4           3         0         127            4   80000.000000  23900000   \n",
       "...       ...       ...         ...          ...            ...       ...   \n",
       "130438      0         1         111            2  100862.291944  48000000   \n",
       "130439      0         1         114            4  100862.291944        -1   \n",
       "130440      3         0         114            3   20000.000000        -1   \n",
       "130441      5         0         135            4  123000.000000   6900000   \n",
       "130442      5         0         160            3   43000.000000  17400000   \n",
       "\n",
       "        year  206  405   83  ...      مشکی  نیسان  هاچ  وانت   وی  پارس  \\\n",
       "0       1393  0.0  0.0  0.0  ...  0.000000    0.0  0.0   0.0  0.0   0.0   \n",
       "1       1366  0.0  0.0  0.0  ...  0.000000    0.0  0.0   0.0  0.0   0.0   \n",
       "2       1381  0.0  0.0  0.0  ...  0.775334    0.0  0.0   0.0  0.0   0.0   \n",
       "3       1372  0.0  0.0  0.0  ...  0.000000    0.0  0.0   0.0  0.0   0.0   \n",
       "4       1391  0.0  0.0  0.0  ...  0.000000    0.0  0.0   0.0  0.0   0.0   \n",
       "...      ...  ...  ...  ...  ...       ...    ...  ...   ...  ...   ...   \n",
       "130438  1393  0.0  0.0  0.0  ...  0.000000    0.0  0.0   0.0  0.0   0.0   \n",
       "130439  1393  0.0  0.0  0.0  ...  0.000000    0.0  0.0   0.0  0.0   0.0   \n",
       "130440  1392  0.0  0.0  0.0  ...  0.000000    0.0  0.0   0.0  0.0   0.0   \n",
       "130441  1379  0.0  0.0  0.0  ...  0.000000    0.0  0.0   0.0  0.0   0.0   \n",
       "130442  1393  0.0  0.0  0.0  ...  0.000000    0.0  0.0   0.0  0.0   0.0   \n",
       "\n",
       "           پراید       پژو  پیکان   کارخانه  \n",
       "0       0.000000  0.000000    0.0  0.000000  \n",
       "1       0.000000  0.000000    0.0  0.000000  \n",
       "2       0.000000  0.488448    0.0  0.000000  \n",
       "3       0.000000  0.000000    0.0  0.000000  \n",
       "4       0.000000  0.000000    0.0  0.667040  \n",
       "...          ...       ...    ...       ...  \n",
       "130438  0.000000  0.000000    0.0  0.000000  \n",
       "130439  0.000000  0.000000    0.0  0.000000  \n",
       "130440  0.000000  0.000000    0.0  0.000000  \n",
       "130441  0.494819  0.000000    0.0  0.000000  \n",
       "130442  0.396567  0.000000    0.0  0.729655  \n",
       "\n",
       "[130443 rows x 47 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='word', min_df=500, max_features=40)  \n",
    "vectorized = vectorizer.fit_transform(train['title'])\n",
    "q = pd.DataFrame(vectorized.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "train[vectorizer.get_feature_names()] = q[vectorizer.get_feature_names()].values\n",
    "train = train.drop('title', 1)\n",
    "train.info()\n",
    "q.info()\n",
    "# train = train.drop('description', 1)\n",
    "\n",
    "\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-document",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "downtown-kuwait",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train.drop('price', 1)\n",
    "y = train.price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-domestic",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "light-appliance",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-186-1ad4ff3637d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmutual_info_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36mmutual_info_regression\u001b[0;34m(X, y, discrete_features, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    365\u001b[0m            \u001b[0mof\u001b[0m \u001b[0ma\u001b[0m \u001b[0mRandom\u001b[0m \u001b[0mVector\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProbl\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mPeredachi\u001b[0m \u001b[0mInf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m23\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1987\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \"\"\"\n\u001b[0;32m--> 367\u001b[0;31m     return _estimate_mi(X, y, discrete_features, False, n_neighbors,\n\u001b[0m\u001b[1;32m    368\u001b[0m                         copy, random_state)\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36m_estimate_mi\u001b[0;34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1e-10\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m     mi = [_compute_mi(x, y, discrete_feature, discrete_target, n_neighbors) for\n\u001b[0m\u001b[1;32m    286\u001b[0m           x, discrete_feature in zip(_iterate_columns(X), discrete_mask)]\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1e-10\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m     mi = [_compute_mi(x, y, discrete_feature, discrete_target, n_neighbors) for\n\u001b[0m\u001b[1;32m    286\u001b[0m           x, discrete_feature in zip(_iterate_columns(X), discrete_mask)]\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36m_compute_mi\u001b[0;34m(x, y, x_discrete, y_discrete, n_neighbors)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_compute_mi_cd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_compute_mi_cc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36m_compute_mi_cc\u001b[0;34m(x, y, n_neighbors)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mnx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mkd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKDTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'chebyshev'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mny\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_radius\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mradius\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mny\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "mi = mutual_info_regression(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "joined-lafayette",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               -1\n",
       "1               -1\n",
       "2          8500000\n",
       "3         19500000\n",
       "4         23900000\n",
       "            ...   \n",
       "130438    48000000\n",
       "130439          -1\n",
       "130440          -1\n",
       "130441     6900000\n",
       "130442    17400000\n",
       "Name: price, Length: 130443, dtype: int64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = pd.Series(mi)\n",
    "mu.index = X_train.columns\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "british-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def train(model,X_train, X_test, y_train):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred= model.predict(X_test)\n",
    "    return y_pred\n",
    "\n",
    "def test(y_test, y_pred):\n",
    "    mse = mean_squared_error(np.array(y_test), y_pred)\n",
    "    rmse = mean_squared_error(np.array(y_test), y_pred, squared = False)\n",
    "    return mse,rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "precious-compression",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(582649135113486.8, 24138126.17237483)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'random_state': [0,42,60],\n",
    "    'max_depth': range(5,70),\n",
    "    'n_estimators': [20,100, 200, 300, 1000]\n",
    "}\n",
    "\n",
    "\n",
    "clf = DecisionTreeRegressor(max_depth = 5)\n",
    "# grid_search = GridSearchCV(estimator = clf, param_grid = param_grid,cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "y_pred = train(clf,X_train, X_test, y_train)\n",
    "mse, rmse = test(y_test, y_pred)\n",
    "\n",
    "mse,rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
